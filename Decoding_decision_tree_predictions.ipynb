{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1600347335465",
   "display_name": "Python 3.6.10 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "+----+----+----+----+----+-----+\n|ball|keep|hall|fall|mall|label|\n+----+----+----+----+----+-----+\n|   0|   4|   8|  12|  16|   21|\n|   1|   5|   9|  13|  17|   31|\n|   1|   6|  10|  14|  18|   41|\n|   3|   7|  11|  15|  10|   51|\n|   1|   7|   2|  15|  10|   51|\n|   0|   4|   6|  12|  16|   51|\n|   1|   6|  10|  14|  18|   21|\n|   3|   7|  11|  15|  10|   31|\n+----+----+----+----+----+-----+\n\n"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pyspark.sql import SparkSession\n",
    "spark_session = SparkSession.builder.getOrCreate()\n",
    "\n",
    "data = pd.DataFrame({\n",
    "    'ball': [0, 1, 1, 3, 1, 0, 1, 3],\n",
    "    'keep': [4, 5, 6, 7, 7, 4, 6, 7],\n",
    "    'hall': [8, 9, 10, 11, 2, 6, 10, 11],\n",
    "    'fall': [12, 13, 14, 15, 15, 12, 14, 15],\n",
    "    'mall': [16, 17, 18, 10, 10, 16, 18, 10],\n",
    "    'label': [21, 31, 41, 51, 51, 51, 21, 31]\n",
    "})\n",
    "\n",
    "df = spark_session.createDataFrame(data)\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.classification import DecisionTreeClassifier\n",
    "from pyspark.ml import Pipeline\n",
    "\n",
    "f_list = ['ball','keep','mall','hall','fall']\n",
    "assemble_numerical_features = VectorAssembler(inputCols=f_list, outputCol='features',\n",
    "                                                      handleInvalid='skip')\n",
    "\n",
    "dt = DecisionTreeClassifier(featuresCol='features', labelCol='label')\n",
    "\n",
    "pipeline = Pipeline(stages=[assemble_numerical_features, dt])\n",
    "model = pipeline.fit(df)\n",
    "df = model.transform(df)\n",
    "dt_m = model.stages[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "DecisionTreeClassificationModel (uid=DecisionTreeClassifier_e24331baf863) of depth 4 with 9 nodes\n  If (feature 3 <= 7.0)\n   Predict: 51.0\n  Else (feature 3 > 7.0)\n   If (feature 2 <= 13.0)\n    Predict: 31.0\n   Else (feature 2 > 13.0)\n    If (feature 0 <= 0.5)\n     Predict: 21.0\n    Else (feature 0 > 0.5)\n     If (feature 1 <= 5.5)\n      Predict: 31.0\n     Else (feature 1 > 5.5)\n      Predict: 21.0\n\n"
    }
   ],
   "source": [
    "print(dt_m.toDebugString)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_debug_string_lines(lines):\n",
    "    \n",
    "    block = []\n",
    "    while lines:\n",
    "\n",
    "        if lines[0].startswith('If'):\n",
    "            bl = ' '.join(lines.pop(0).split()[1:]).replace('(', '').replace(')', '')\n",
    "            block.append({'name': bl, 'children': parse_debug_string_lines(lines)})\n",
    "\n",
    "            if lines[0].startswith('Else'):\n",
    "                be = ' '.join(lines.pop(0).split()[1:]).replace('(', '').replace(')', '')\n",
    "                block.append({'name': be, 'children': parse_debug_string_lines(lines)})\n",
    "        elif not lines[0].startswith(('If', 'Else')):\n",
    "            block2 = lines.pop(0)\n",
    "            block.append({'name': block2})\n",
    "        else:\n",
    "            break\n",
    "    \n",
    "    return block\n",
    "\n",
    "def debug_str_to_json(debug_string):\n",
    "    data = []\n",
    "    for line in debug_string.splitlines():\n",
    "        if line.strip():\n",
    "            line = line.strip()\n",
    "            data.append(line)\n",
    "        else:\n",
    "            break\n",
    "        if not line: break\n",
    "    json = {'name': 'Root', 'children': parse_debug_string_lines(data[1:])}\n",
    "    return json\n",
    "\n",
    "tree_as_dict = debug_str_to_json(dt_m.toDebugString)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "{'name': 'Root',\n 'children': [{'name': 'feature 3 <= 7.0',\n   'children': [{'name': 'Predict: 51.0'}]},\n  {'name': 'feature 3 > 7.0',\n   'children': [{'name': 'feature 2 <= 13.0',\n     'children': [{'name': 'Predict: 31.0'}]},\n    {'name': 'feature 2 > 13.0',\n     'children': [{'name': 'feature 0 <= 0.5',\n       'children': [{'name': 'Predict: 21.0'}]},\n      {'name': 'feature 0 > 0.5',\n       'children': [{'name': 'feature 1 <= 5.5',\n         'children': [{'name': 'Predict: 31.0'}]},\n        {'name': 'feature 1 > 5.5',\n         'children': [{'name': 'Predict: 21.0'}]}]}]}]}]}"
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "tree_as_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "{'numeric': [{'idx': 0, 'name': 'ball'},\n  {'idx': 1, 'name': 'keep'},\n  {'idx': 2, 'name': 'mall'},\n  {'idx': 3, 'name': 'hall'},\n  {'idx': 4, 'name': 'fall'}]}"
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "df.schema['features'].metadata[\"ml_attr\"][\"attrs\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_type_to_flist_dict = df.schema['features'].metadata[\"ml_attr\"][\"attrs\"]\n",
    "f_index_to_name_dict = {}\n",
    "for f_type, f_list in f_type_to_flist_dict.items():\n",
    "\n",
    "    for f in f_list:\n",
    "        f_index = f['idx']\n",
    "        f_name = f['name']\n",
    "        f_index_to_name_dict[f_index] = f_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "{0: 'ball', 1: 'keep', 2: 'mall', 3: 'hall', 4: 'fall'}"
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "f_index_to_name_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import operator\n",
    "\n",
    "operators = {\n",
    "            \">=\": operator.ge,\n",
    "            \"<=\": operator.le,\n",
    "            \">\": operator.gt,\n",
    "            \"<\": operator.lt,\n",
    "            \"==\": operator.eq,\n",
    "            'and': operator.and_,\n",
    "            'or': operator.or_\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import udf, lit\n",
    "from pyspark.sql.types import StringType, ArrayType, DoubleType\n",
    "import ast\n",
    "\n",
    "def generate_rules(dt_as_json, df, f_index_to_name_dict, operators):\n",
    "\n",
    "    dt_as_json_str = str(dt_as_json)\n",
    "    cond_parsing_exception_occured = False\n",
    "\n",
    "    df = df.withColumn('features'+'_list',\n",
    "                            udf(lambda x: x.toArray().tolist(), ArrayType(DoubleType()))\n",
    "                            (df['features'])\n",
    "                        )\n",
    "    # step 3 : parse and check whether current instance follows condition in perticular node\n",
    "    def parse_validate_cond(cond: str, f_vector: list):\n",
    "\n",
    "        cond_parts = cond.split()\n",
    "        condition_f_index = int(cond_parts[1])\n",
    "        condition_op = cond_parts[2]\n",
    "        condition_value = float(cond_parts[3])\n",
    "\n",
    "        f_value = f_vector[condition_f_index]\n",
    "        f_name = f_index_to_name_dict[condition_f_index].replace('numerical_features_', '').replace('encoded_numeric_', '').lower()\n",
    "\n",
    "        if operators[condition_op](f_value, condition_value):\n",
    "            return True, f_name + ' ' + condition_op + ' ' + str(round(condition_value,2))\n",
    "\n",
    "        return False, ''\n",
    "        \n",
    "# Step 4 : extract rules for an instance in a dataframe, going through nodes in a tree where instance is satisfying the rule, finally leading to a prediction node\n",
    "    def extract_rule(dt_as_json_str: str, f_vector: list, rule=\"\"):\n",
    "        \n",
    "        # variable declared in outer function is read only\n",
    "        # in inner if not explicitly declared to be nonlocal\n",
    "        nonlocal cond_parsing_exception_occured\n",
    "\n",
    "        dt_as_json = ast.literal_eval(dt_as_json_str)\n",
    "        child_l = dt_as_json['children']\n",
    "\n",
    "        for child in child_l:\n",
    "            name = child['name'].strip()\n",
    "\n",
    "            if name.startswith('Predict:'):\n",
    "                # remove last comma\n",
    "                return rule[0:rule.rindex(',')]\n",
    "\n",
    "            if name.startswith('feature'):\n",
    "                try:\n",
    "                    res, cond = parse_validate_cond(child['name'], f_vector)\n",
    "                except Exception as e:\n",
    "                    res = False\n",
    "                    cond_parsing_exception_occured = True\n",
    "                if res:\n",
    "                    rule += cond +', '\n",
    "                    rule = extract_rule(str(child), f_vector, rule=rule)\n",
    "        return rule\n",
    "\n",
    "    df = df.withColumn('rule',\n",
    "                        udf(lambda dt, fv:extract_rule(dt, fv) ,StringType())\n",
    "                        (lit(dt_as_json_str), df['features'+'_list'])\n",
    "                    )\n",
    "    # log exception occured while trying to parse\n",
    "    # condition in decision tree node\n",
    "    if cond_parsing_exception_occured:\n",
    "        print('some node in decision tree has unexpected format')\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = generate_rules(tree_as_dict,df,f_index_to_name_dict,operators)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "result_rows = df.select('ball','keep','hall','fall','mall','prediction','rule').collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "[Row(ball=0, keep=4, hall=8, fall=12, mall=16, prediction=21.0, rule='hall > 7.0, mall > 13.0, ball <= 0.5'),\n Row(ball=1, keep=5, hall=9, fall=13, mall=17, prediction=31.0, rule='hall > 7.0, mall > 13.0, ball > 0.5, keep <= 5.5'),\n Row(ball=1, keep=6, hall=10, fall=14, mall=18, prediction=21.0, rule='hall > 7.0, mall > 13.0, ball > 0.5, keep > 5.5'),\n Row(ball=3, keep=7, hall=11, fall=15, mall=10, prediction=31.0, rule='hall > 7.0, mall <= 13.0'),\n Row(ball=1, keep=7, hall=2, fall=15, mall=10, prediction=51.0, rule='hall <= 7.0'),\n Row(ball=0, keep=4, hall=6, fall=12, mall=16, prediction=51.0, rule='hall <= 7.0'),\n Row(ball=1, keep=6, hall=10, fall=14, mall=18, prediction=21.0, rule='hall > 7.0, mall > 13.0, ball > 0.5, keep > 5.5'),\n Row(ball=3, keep=7, hall=11, fall=15, mall=10, prediction=31.0, rule='hall > 7.0, mall <= 13.0')]"
     },
     "metadata": {},
     "execution_count": 22
    }
   ],
   "source": [
    "result_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}